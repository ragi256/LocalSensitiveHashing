
index
1.概要
2.大まかな流れ
3.具体例

[==================== 概要 ====================]
大量のツイートデータから、内容の似ているツイート(パクリツイート)を高速に検出します。
高速化にLocal Sensitive Hashingアルゴリズム(LSH)を用いています。
検出に用いるプログラムは以下の4つです(実行順)
 - setData
 - convertStream
 - searchID
 - calculateDistance
compareTestProgram, spreadCompareTestProgram, systemAssesmentはLSHを用いなかった通常プログラムとの比較テスト用のプログラムです。
sparead版はツイートデータが増えてcompareTestProgramでは処理し切れなくなった時のために処理を分散させたバージョンです。ただし、単にループを100分割しているだけなので、分散処理を行なっているわけではありません。

[=============== 大まかな流れ =================]
入力データとしてMeCabで形態素解析を行ったツイートデータを利用します。
各プログラムごとに経過確認のためログデータを出力します。
次の処理には直前の処理で出力したログデータを入力とします。

(setData)
単語ごとに分割されたツイートの中から自動詞である単語の原形を拾います。
この際、ツイートをベクトル、単語を各要素とみなして正規化を行い各次元の値を計算します。
入力:MeCabによって形態素解析をしたツイートデータ
出力:ツイートID, 正規化した値, 単語リスト 

(convertStream)
LSHにより各ツイートの正規化した値と単語リストからツイートをビットストリームに変換します。
この際パラメータとしてbit数を入力します。
bit数が大きければ精度は上がりますが、その分処理が低速になります。
入力:ツイートID, 正規化した値, 単語リスト
出力:ツイートID，ビットストリーム(2進数)

(searchID)
ビット化されたツイートを解析し、ビットストリームが似ているツイートIDを抽出します。
入力:ツイートID, ビットストリーム
出力:ツイートID, 似ているIDのリスト

(calculateDistance)
searchIDによって絞りこまれたツイートが似ているIDのリストを用いて実際の近似度を計算します。
計算の結果近似度が一定以上であった場合標準出力に表示します。
入力:ツイートID, 似ているIDのリスト
出力:ツイートID1 ツイートID2 ID1とID2の近似度

[=================== 具体例 ===================]

input:

